{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Spotify Popularity Analysis Notebook**\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1- Introduction and setup\n","This Jupyter Notebook is part of the Spotify Popularity Analysis project. In this notebook, we will begin by importing the necessary Python libraries for data analysis and visualization. After that, we will proceed with data processing and analysis.\n","\n","### Importing Libraries\n","\n","Let's start by importing the required libraries for our analysis:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from ipywidgets import interact\n","import datetime\n","import statsmodels.api as sm\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the data\n","\n","In this section, we will load the Spotify dataset for the year 2023. We have defined the path to the CSV file and will use the 'ISO-8859-1' encoding for reading the data. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the project's root directory\n","project_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n","\n","# Define the path to the CSV file relative to the project directory\n","csv_file_path = os.path.join(project_dir, 'data/spotify-2023.csv')\n","\n","# Load the data (CSV format) with 'ISO-8859-1' encoding\n","data = pd.read_csv(csv_file_path, encoding='ISO-8859-1')"]},{"cell_type":"markdown","metadata":{},"source":["## 2- Data Exploration\n","\n","This dataset contains a comprehensive list of the most famous songs of 2023 as listed on Spotify. It offers insights into each song's attributes, popularity, and presence on various music platforms. Key features include:\n","\n","- `track_name`: Name of the song\n","- `artist(s)_name`: Name of the artist(s) of the song\n","- `artist_count`: Number of artists contributing to the song\n","- `released_year`: Year of song release\n","- `released_month`: Month of song release\n","- `released_day`: Day of the month of song release\n","- `in_spotify_playlists`: Number of Spotify playlists the song is in\n","- `in_spotify_charts`: Presence and rank on Spotify charts\n","- `streams`: Total streams on Spotify\n","- `in_apple_playlists`: Number of Apple Music playlists the song is in\n","- `in_apple_charts`: Presence and rank on Apple Music charts\n","- `in_deezer_playlists`: Number of Deezer playlists the song is in\n","- `in_deezer_charts`: Presence and rank on Deezer charts\n","- `in_shazam_charts`: Presence and rank on Shazam charts\n","- `bpm`: Beats per minute (song tempo)\n","- `key`: Key of the song\n","- `mode`: Mode of the song (major or minor)\n","- `danceability_%`: Percentage indicating dance suitability\n","- `valence_%`: Positivity of musical content\n","- `energy_%`: Perceived energy level\n","- `acousticness_%`: Amount of acoustic sound\n","- `instrumentalness_%`: Amount of instrumental content\n","- `liveness_%`: Presence of live performance elements\n","- `speechiness_%`: Amount of spoken words\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Data Overview"]},{"cell_type":"markdown","metadata":{},"source":["##### Dataset Structure\n","\n","First, let's explore the structure of the dataset to gain insights into its and features:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Display the first few rows of the dataset\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["##### Dataset Dimension\n","\n","Let's check the dimensions of the dataset:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check the structure of the dataset\n","num_rows, num_columns = data.shape\n","\n","num_rows, num_columns"]},{"cell_type":"markdown","metadata":{},"source":["##### Column Data Types\n","\n","Display the data types of all columns in the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check data types of all columns\n","data.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 Data Cleaning"]},{"cell_type":"markdown","metadata":{},"source":["##### Missing Values\n","Now, we'll check for missing values in the dataset and decide how to handle them. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check for missing values\n","missing_values = data.isnull().sum()\n","\n","# Display columns with missing values\n","missing_columns = missing_values[missing_values > 0]\n","missing_columns\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Remove columns with missing values\n","data.drop(columns=missing_columns.index, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["##### Handling Duplicates\n","Next, let's address duplicate rows in the dataset. We'll remove them if necessary."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check for duplicate rows\n","duplicate_rows = data[data.duplicated(keep='first')]\n","duplicate_rows\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Remove duplicate rows\n","data = data.drop_duplicates(keep='first')"]},{"cell_type":"markdown","metadata":{},"source":["##### Data Type Conversions\n","Finally, we'll perform data type conversions to remove non-numeric values from streams column and convert to numeric values."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert streams column to integers.\n","data['streams'] = pd.to_numeric(data['streams'], errors='coerce')\n","\n","# Check data types again to confirm the conversion\n","data.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["### 2.3 Summary Statistics "]},{"cell_type":"markdown","metadata":{},"source":["##### Basic Statistics\n","Let's start by calculating summary statistics for the numerical columns, including measures like mean, median, standard deviation, minimum, and maximum values."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["numerical_summary = data.describe()\n","numerical_summary"]},{"cell_type":"markdown","metadata":{},"source":["##### Data Distribution\n","Next, we'll visualize the distribution of numerical data using histograms."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create histograms for numerical columns\n","numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n","for column in numerical_columns:\n","    plt.figure(figsize=(8, 6))\n","    sns.histplot(data[column], kde=True)\n","    plt.title(f'Distribution of {column}')\n","    plt.xlabel(column)\n","    plt.ylabel('Frequency')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
